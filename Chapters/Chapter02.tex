%************************************************
\chapter{Materiales y M\'etodos}\label{ch:matmet}
%************************************************

Este capítulo describe los materiales y métodos empleados para el ajuste de parámetros de los modelos de ecuaciones de Glass de la vía de señalización de speract presentada en el capítulo anterior y la red de tres nodos del apéndice \ref{ch:3Nodos}. Define los datos experimentales que se usaron para la comparación, las funciones objetivo y estrategias de búsqueda, así como mencionar detalles de la implementación computacional de los programas.

\section{Datos experimentales}
Los datos experimentales que se usaron en todas las comparaciones para discriminar modelos de ecuaciones de Glass corresponden a mediciones de fluorescencia de \ac{ca} obtenidos en el laboratorio del Dr. Alberto Darszon. Un ejemplo de estas mediciones se muestra en la figura \ref{fig:fluorescencia}. Como se mencionó en la sección \ref{sec:spSigNet} del capítulo \ref{ch:antecedentes}, los detalles experimentales de la obtención de estas mediciones se describen a profundidad en \citeauthor{Darszon2008} \citep{Darszon2008} y \citeauthor{Wood2007} \citep{Wood2007}. 

Es importante recalcar que la fluorescencia de calcio es el único tipo de dato experimental que cuenta con mediciones largas (del órden de 10 segundos, aproximadamente).

\section{Funciones objetivo}\label{ch2funcObj}

Como se mencionó en \ref{ch1FuncComp}, es necesario establecer una noción de distancia para determinar qué tan bueno es el ajuste a las mediciones experimentales de un modelo de ecuaciones de Glass con un conjunto de parámetros determinado. Para este efecto, anteriormente se mencionó que los criterios que pueden ayudar a esta determinación son el Error Cuadrático Medio \ref{MSE}, el Índice de Correlación de Pearson \ref{pearson} y el Índice de Pendiente \ref{slopeIndex}.

Se definieron funciones de costo para los anteriores criterios. En cada función, $\mathbf{X}$ representa a las mediciones experimentales, $\mathbf{Y}$ representa a los datos del modelo de ecuaciones de Glass. Finalmente, $X_i$ y $Y_i$ representan a cada uno de los puntos de la medición y de la solución de las ecuaciones de Glass, respectivamente. Cabe recalcar que las únicas mediciones experimentales con las que se cuenta son las de fluorescencia de \ac{ca}, y por lo tanto, los datos del modelo que se compararon con esas mediciones fueron los correspondientes a la dinámica del nodo de \ac{calintra}.

Las funciones son

\begin{eqnarray}
f_{MSE}(\mathbf{X},\mathbf{Y}) & = & \frac{1}{n} (Y_i - X_i)^2\\
f_{Pearson}(\mathbf{X},\mathbf{Y}) & = & 1 - r_{\mathbf{X},\mathbf{Y}}\\
f_{SI}(\mathbf{X},\mathbf{Y}) & = & 1 - \mathrm{SI}(X,Y)
\end{eqnarray}
\\
donde $r_{\mathbf{X},\mathbf{Y}}$ es el Coeficiente de Correlación de Pearson, definido en \ref{pearsonEQ}, SI es el Índice de Pendiente, definido en \ref{siEQ}. De la definición de el Coeficiente de Correlación de Pearson y del Índice de Pendiente, se puede ver que $1 - r_{\mathbf{X},\mathbf{Y}} = 2$, si $r_{\mathbf{X},\mathbf{Y}} = -1$, es decir, cuando $\mathbf{X}$ y $\mathbf{Y}$ están correlacionados negativamente, mientras que $1 - r_{\mathbf{X},\mathbf{Y}} = 0$, si $r_{\mathbf{X},\mathbf{Y}} = 1$, es decir, cuando la correlación entre los datos experimentales y el modelo es perfecta. Entonces, minimizar $f_{Pearson}(\mathbf{X},\mathbf{Y})$ permite elegir un modelo que produzca los datos $Y$ tal que la similitud con los experimentos sea mayor. Un argumento similar muestra que minimizar $f_{SI}(\mathbf{X},\mathbf{Y})$ permite seleccionar un modelo que produzca datos $Y$ con una similitud mayor a los datos experimentales.

%
%\subsubsection{Sparsity Promoting Regularization}
%
%Una alternativa a otro tipo de comparaciones es la \textsc{Regularización Promotora de Dispersión o Sparsity Promoting Regularization}, \citeauthor{Engl2009}. La idea consiste en imputar un modelo estadístico a la comparación de mediciones experimentales con modelos de ecuaciones diferenciales. Los operadores diferenciales que no incluyen componentes estocásticos suelen producir trayectorias por lo general suaves, en contraste con la variabilidad existente en las series de tiempo de las mediciones experimentales. 
%
%Sea $\mathbf{p}$ el vector de parámetros de un conjunto de ecuaciones diferenciales. Sea $\Phi(\mathbf{p},t)$ la trayectoria solución dependiente del tiempo $t$ y del vector de parámetros $\mathbf{p}$. Sea $\Psi(\Phi(\mathbf{p},t))$ un modelo Gaussiano del ruido de las mediciones experimentales con desviación estándar constante. El objetivo de añadir $\Phi$  es imputar un criterio estadístico a la trayectoria solución de la ecuación diferencial, y hacer entonces una comparación entre un modelo estadísticos y un conjunto de datos.
%
%Bajo este esquema, se puede buscar minimizar
%\begin{equation}
%J(\mathbf{p}) = \| \Psi(\Phi(\mathbf{p},t)) - X\|_2^2 -\beta \| \mathbf{p} \| _1^1
%\end{equation}
%donde $\beta \in (0,1)$ es un término promotor de la regularización, que se utiliza para ponderar mediante la norma a 1 el desempeño del vector de parámetros $\mathbf{p}$, mientras que $X$ representa los datos contra los cuales se compara el modelo. 

\section{Estrategias de Búsqueda}

En este trabajo, las estrategias de exploración utilizadas fueron \textsc{Búsqueda Aleatoria}, \textsc{Algoritmos Genéticos} y \textsc{Evolución Diferencial}, cada uno de los cuales se describe a continuación.

\subsubsection{Búsqueda Aleatoria}

La búsqueda aleatoria es la más simple de las estrategias de búsqueda. Consiste en elegir al azar una solución, evaluarla y, si y solo si su costo es mejor que el mejor costo hasta el momento, guardar la solución como la mejor hasta el momento; en caso contrario no se guarda la solución ni se actualiza el valor del mejor costo. En ambos casos, si no se ha llegado a una precisión determinada para la función de costo o bien se ha alcanzado un número máximo de iteraciones, la búsqueda finaliza; en caso contrario, se elige otra solución al azar y se repite el proceso.

\subsubsection{Algoritmos Genéticos}

Inspirados en el trabajo de \citeauthor{holland1975} \citep{holland1975} y tratados de manera un poco más rigurosa por \citeauthor{Goldberg1989} \citep{Goldberg1989}, los algoritmos genéticos son una estrategia de búsqueda que simula el proceso de evolución natural a través de los procesos de cruza, mutación y selección.

El agoritmo inicia con un conjunto de agentes denominados población, donde cada agente tiene un \emph{genoma}, es decir, una representación codificada de una solución al problema de optimización. Posteriormente se selecciona a algunos individuos de la población para procrear a la siguiente generación. La selección se realiza mediante diferentes esquemas, aunque en términos generales se suele favorecer a aquellos individuos que tengan un mejor costo. Los individuos no seleccionados no sobreviven. De entre aquellos que sí han sido seleccionados, se eligen pares de agentes y estos combinan su genoma de acuerdo a algún esquema para crear un tercer agente. Este proceso de cruza se realiza hasta completar una cantidad preestablecida de miembros de la nueva generación. Con cierta probabilidad, por lo general baja, algunos individuos de la nueva población sufrirán una mutación en su genoma. El proceso de selección, cruza y mutación continúa hasta que se ha alcanzado cierta precisión en el costo de la solución o bien se ha alcanzado un número determinado de iteraciones.

Tradicionalmente el genoma y los operadores de los algoritmos genéticos son discretos. Dado que los parámetros que se requirió estimar en este trabajo toman valores continuos, se usó una variante de los algoritmos genéticos tradicionales, adaptados a trabajar con variables continuas encontrado en \citeauthor{Haupt1998} \citep{Haupt1998}, en donde el genoma de un agente se codifica como un vector de valores continuos y los operadores de cruza y mutación pueden ser aplicados a este tipo de variables.

\subsubsection{Evolución Diferencial}\label{difEvol}

\citeauthor{Storn1997} \citep{Storn1997} observaron que algunos métodos heurísticos existentes no eran tan robustos y no convergían tan rápidamente al ser aplicados a problemas de optimización que involucraran variables continuas. A raíz de esto, desarrollaron un método específicamente pensado para este tipo de problemas. 

El método consiste en una población de soluciones candidato, llamadas agentes. Cada agente se mueve a través del espacio de búsqueda combinando las posiciones de los agentes existentes en la población. Si la nueva posición del agente representa una mejora, esta nueva posición se acepta y pasa a formar parte de la población; en caso contrario, la nueva posición se rechaza. El proceso se repite y se espera que una solución satisfactoria se descubrirá eventualmente.

Sea $x \in \mathbb{R}^n$ un agente en la población de tamaño $NP>3$; sea $F \in [0,2]$, conocido como peso diferencial; sea también $CR \in [0,1]$, la probabilidad de cruza. El algoritmo de evolución diferencial consiste en:
\begin{enumerate}
\item Inicializar cada agente $x$ con una posición aleatoria en el espacio de búsqueda.
\item Hasta que un criterio de búsqueda sea satisfecho, repetir:
	\begin{enumerate}
		\item Escoger al azar tres agentes distintos entre sí $a$, $b$, $c$.
		\item Escoger un índice al azar $R \in {1,\ldots,n}$ donde $n$ es la dimensionalidad del problema
		\item Calcular la posible nueva posición del agente, dada por $y=[y_1,\ldots,y_n]$ iterando sobre cada $i \in {1,\ldots,n}$ como sigue:
			\begin{enumerate}
				\item Elegir al azar de manera uniforme $r \in (0,1)$
				\item Si $i=R$ o $r_i<CR$, hacer $y_i=a_i+F(b_i-c_i)$. En caso contrario $y_i=x_i$
			\end{enumerate}
		\item Si $f(y)<f(x)$, entonces $x=y$
	\end{enumerate}
\item Elegir el agente con el menor costo o máxima adaptación y regresarlo como la mejor solución candidato encontrada.
\end{enumerate}

La elección de $F$, $CR$ y $NP$ puede tener un impacto significativo en el desempeño de la optimización. \citeauthor{Storn1997}  \citep{Storn1997}, y \citeauthor{lampinen2002} \citep{lampinen2002} proporcionan valores iniciales para estos parámetros que parecen ser un buen punto de partida en general.

\section{Búsqueda de parámetros}

La búsqueda de parámetros para los modelos de ecuaciones de Glass se realizó usando diferentes combinaciones de funciones objetivo y estrategias de búsqueda. La implementación de las rutinas se realizó en lenguaje C \citeauthor{Kernighan1988} \citep{Kernighan1988} bajo el estándar \textsc{iso c99} publicado por  \citeauthor{c99} \citep{c99} usando el compilador \textsc{clang} de \citeauthor{clang} \citep{clang}. Adicionalmente, se usaron los módulos de estadística, métodos de solución de ecuaciones diferenciales ordinarias, vectores y matrices, y generación de números aleatorios de la biblioteca de funciones para cómputo científico \textsc{GNU Scientific Library (GSL) v.1.15} \citeauthor{gslManual} \citep{gslManual}.

Para la solución de ecuaciones diferenciales se utilizó el método de Euler \citeauthor{numrecipesc} \citep{numrecipesc}. También se utilizaron el método de Runge-Kutta 4,5 \citeauthor{numrecipesc} \citep{numrecipesc}, \citeauthor{gslManual} \citep{gslManual}; y el método de paso adaptativo de Adams-Bashforth \citep{gslManual}. Estos dos últimos métodos son menos sensibles a errores que el método de Euler original.

El método de Euler se implementó directamente, mientras que para el caso del método de Runge-Kutta 4,5 y del método de Adams-Bashforth se utilizó la implementación de la \textsc{GNU Scientific Library (GSL) v.1.15}. La generación de números aleatorios se realizó usando la implementación de la \textsc{GNU Scientific Library (GSL) v.1.15} del algoritmo \textsc{ranlxs2} \citeauthor{gslManual} \citep{gslManual}.

Como esquema general, los programas de inferencia de parámetros consistían en proponer soluciones candidato y evaluarlas, repitiendo el proceso hasta cumplir con un criterio de paro. Una solución candidato consiste en un conjunto de parámetros propuestos de acuerdo a una estrategia de exploración del espacio de búsqueda y las trayectorias solución del problema de condiciones iniciales del sistema de ecuaciones de Glass correspondiente a dichos parámetros. La evaluación de soluciones candidato consistió en calcular su costo de acuerdo a las funciones objetivo de la sección \ref{ch2funcObj}, para las cuales $X$ son las mediciones experimentales de fluorescencia de calcio y $Y$ la dinámica del nodo de \ac{calintra} del modelo de Glass dado por un conjunto de parámetros particulares.

\section{Resumen}
En este capítulo se definieron las herramientas necesarias para implementar los programas de búsqueda de parámetros de los modelos de ecuaciones de Glass de la vía de señalización de speract presentada en el capítulo anterior y la red de tres nodos del apéndice \ref{ch:3Nodos}. El siguiente capítulo muestra y discute los resultados de la ejecución de las estrategias de búsqueda.
