%************************************************
\chapter{Materiales y M\'etodos}\label{ch:matmet} % $\mathbb{ZNR}$
%************************************************
Este capítulo comienza con una discusión de los alcances y limitaciones del modelo discreto a manera de motivación y justificación para el desarrollo de este trabajo. Posteriormente introduce el formalismo de ecuaciones de Glass; plantea el problema de la estimación de parámetros como un problema de optimización, describiendo las nociones de distancia usadas para comparar la dinámica de calcio de Glass con mediciones experimentales; finalmente aborda brevemente el procedimiento seguido para poner en marcha la búsqueda de parámetros.

\section{Alcances del modelo discreto}

La utilidad del modelo discreto presentado en el capítulo anterior, radica en que a través de una aproximación de grano grueso es posible hacer comparaciones entre modelo y experimentos en intervalos de tiempo relativamente \emph{grandes}, en el sentido que una oscilación se corresponde con cuatro unidades de tiempo de simulación. 

Resulta interesante que aún a este nivel grueso de resolución temporal y de estado, fue posible corroborar la validez del modelo mediante la comparación con comportamientos observados experimentalmente con antelación, además de predecir comportamientos no observados previamente, para los cuales se diseñaron experimentos específicos que corroboraron dicha predicción.

\section{Limitaciones del modelo discreto}

Una de las limitaciones de dicho modelo consiste en que el sistema es sincronizado, es decir, todos los nodos actualizan su estado con el mismo esquema temporal. Esta actualización sincronizada es particularmente válida en tanto que el estado del nodo es un promedio en un intervalo de tiempo cuya duración es mayor que el tiempo en el que se dan las reacciones bioquímicas de la red. Al mismo tiempo que proporciona validez a una aproximación sincronizada, el describir al sistema en intervalos de actualización largos es también una desventaja. Finalmente, la discretización de las variables de estado es adecuada para tener una idea general --no particular-- de la dinámica del sistema. 

\section{Ecuaciones de Glass}

Una opción de modelación intermedia entre los modelos discretos y los basados en las EDOs son los de dinámica semicontinua. Entre este tipo de modelos se encuentran las ecuaciones lineales por pedazos que fueron esbozadas por Glass en \citeauthor{Glass1973} \citep{Glass1973}, consistentes en definir una derivada cuya forma específica depende del valor de un mapeo discreto en un intervalo de tiempo pequeño. 

\subsection{Construcción de las ecuaciones de Glass}

Consideremos de nuevo el mapeo discreto \ref{eqn:kaufman}, presentado en el capítulo \ref{ch:antecedentes}.
Es posible escribirlo también como

\begin{equation}
\sigma_i(t+\tau_i)=F_i[\sigma_{i_1}(t),\sigma_{i_2}(t),\ldots,\sigma_{i_k}(t)]
\end{equation}
\\
donde $\tau_i=1$. Si $\tau_i \rightarrow 0$, haciendo un desarrollo en serie de Taylor de $\sigma_i(t+\tau_i)$ hasta la derivada de primer orden, para posteriormente despejar esa derivada se obtiene

\begin{equation}
\frac{\sigma_i(t)}{dt} = \frac{1}{\tau_i} [\sigma_i(t+\tau_i) - \sigma_i(t)]
\end{equation}
\\
y sustituyendo $\sigma_i(t+\tau_i)$ por 

\begin{equation}
F_i[H(\sigma_{i_1}(t), \theta_{i_1}), H(\sigma_{i_2}(t), \theta_{i_2}),\ldots, H(\sigma_{i_k}(t), \theta_{i_k})]
\end{equation}
\\
obtenemos 

\begin{equation}
\frac{\sigma_i(t)}{dt} = \frac{1}{\tau_i} (F_i[H(\sigma_{i_1}(t), \theta_{i_1}), H(\sigma_{i_2}(t), \theta_{i_2}),\ldots, H(\sigma_{i_k}(t), \theta_{i_k})] - \sigma_i(t))
\end{equation} 
\\
donde $\frac{1}{\tau_i}$ es el inverso del tamaño del intervalo donde se hace el desarrollo en serie de Taylor, $H(\sigma_{i_1}, \theta_{i_1})$ es una función escalón que discretiza los valores de estado del nodo $i_1$ usando un valor de umbral $\theta_{i_1}$. Esta discretización es necesaria puesto que la variable de estado es ahora una variable continua, al igual que el tiempo, mientras que $F_i$ sigue siendo el mismo mapeo discreto.

Mediante este procedimiento, es posible contar con una descripción semicontinua de la dinámica del sistema, en tanto que la derivada de cada nodo no es única sino que depende del valor de la función discreta en cada intervalo de tamaño $\tau_i$. A este tipo de ecuaciones se les conoce también como \emph{Piecewise Linear Differential Equations}, o Ecuaciones Diferenciales Lineales por Pedazos.
%% (Conviene tener una gráfica que ilustre por qué esto es realmente un mapeo piecewise linear, o de manera equivalente mostrar formalmente una de las ecuaciones diferenciales como un mapeo)

\subsection{Ventajas y desventajas}

El beneficio directo de usar este formalismo es contar con un refinamiento de la descripción proporcionada por el modelo discreto, a la par que se construye este refinamiento a partir del modelo existente. Dado que el modelo discreto es construído a partir de observaciones y conocimiento biológico, las ecuaciones de Glass no son un formalismo \emph{ad hoc} que reproduce el comportamiento de un sistema a través de arbitrariamente ajustar trayectorias, sino que se basan en un conjunto de observaciones y conocimiento previo.

El costo por usar este formalismo radica en la estimación de los valores de umbral para cada nodo de la red. En el caso de que se quiera un modelo sincronizado, los tiempos característicos, que denotamos como $\alpha_i=\frac{1}{\tau_i}$ pueden establecerse todos iguales. En particular, el modelo discreto en tiempo se recupera al establecer el tiempo característico en $\tau_i = 1,\ \forall i$.

\section{Estimación de parámetros}

Al plantear un modelo semicontinuo basado en ecuaciones de Glass es necesario hacer estimación de parámetros. Estos parámetros son los umbrales de activación de cada nodo, además de los inversos del tamaño de cada uno de los intervalos de tiempo.

Los parámetros deben elegirse de modo que la dinámica del sistema y de los nodos en particular sea coherente desde un punto de vista biológico. En el caso de la vía de señalización, objeto de estudio de esta tesis, los parámetros a encontrar fueron aquellos tales que reprodujeran el comportamiento del calcio intracelular observado experimentalmente. Se tomó en consideración solamente la similitud en la dinámica de calcio del sistema debido a que este es el único tipo de dato experimental que cuenta con mediciones largas. Un ejemplo de estas mediciones se muestra en la figura \ref{fig:fluorescencia}.

En este sentido, el problema de construir un modelo semicontinuo usando ecuaciones de Glass se reduce, después de escribir las ecuaciones, en un problema de estimación de parámetros. En tanto problema de optimización, es necesario definir una función objetivo que minimizar (o maximizar) y contar con una estrategia de exploración del espacio de parámetros. 

De manera formal, sea $f(p)$ la función de costo a minimizar (o función de adaptación a maximizar), donde $f:\mathbb{R}^n\rightarrow \mathbb{R}$ y $p$ es un vector de números reales. El valor de la función $f(p)$ indica la adaptación o costo del vector $p$. Típicamente, en muchos problemas el gradiente de $f$ es desconocido. El objetivo consiste en encontrar un $m \in \mathbb{R}^n$ tal que $f(m) \le f(p),\ \forall p \in \mathbb{R}^n$. En el caso de maximización, basta con definir la función $h=-f$. En este trabajo se optó por la minimización de funciones objetivo.

\subsection{Funciones objetivo}

Es necesario establecer una noción de distancia para determinar si la serie temporal proveniente de los experimentos de fluorescencia de calcio corresponde con la trayectoria del nodo de calcio del modelo de ecuaciones semicontinuas.

Existen varias maneras de comparar series de tiempo, desde técnicas generales y ampliamente usadas como el \emph{Error Cuadrático Medio} \textsc{(mse)} \citep{msewiki}, el \emph{Coeficiente de Correlación de Pearson} \citep{pearsoncorrwiki}, hasta aquellas que fueron diseñadas con el objetivo de establecer la similitud entre series de tiempo surgidas de procesos biológicos, como el \emph{Índice de Pendiente o Slope Index} \textsc{(si)} \citeauthor{Cho2006} \citep{Cho2006}.% Además se pueden usar algunos otros criterios que califiquen la similitud de dos trayectorias basados no solo en la distancia sino en propiedades específicas de un conjunto de parámetros que influyen sobre esa dinámica. En este último grupo se encuentra la \emph{Regularización Promotora de Dispersión o Sparsity Promoting Regularization} \citeauthor{Engl2009}.%(Van der Boos, Engels 2009, Vogel).

\subsubsection{Error Cuadrático Medio (MSE)}


El \textsc{mse} \citep{msewiki} es el valor esperado de la diferencia entre las observaciones y la respuesta, trayectoria o dinámica predecida por un modelo. Al ser minimizado, es posible discriminar entre distintos modelos, estableciendo cuál de entre un conjunto de modelos ajusta mejor, es decir, explica mejor los datos. El \textsc{mse} está dado por $E[\hat{(\theta} - \theta)^2]$.

\subsubsection{Coeficiente de correlación de Pearson}

El Coeficiente de Correlación de Pearson \citep{pearsoncorrwiki} es una medida de la correlación (dependencia lineal) entre dos variables $X$ y $Y$, denotado por $r \in [-1, 1]$, donde
\begin{equation} 
r = \frac{\sum_{i=1}^n (X_i - \bar{X})(Y_i - \bar{Y})} {\sqrt{\sum_{i=1}^n (X_i - \bar{X})^2} \sqrt{\sum_{i=1}^n (Y_i - \bar{Y})^2}}
\end{equation}

\subsubsection{Índice de Pendiente (SI)}

Propuesto por \citeauthor{Cho2006} \citep{Cho2006}, el índice de pendiente entre dos series de tiempo $X$ y $Y$ consiste en ponderar la suma de los signos de las derivadas entre los puntos de ambas series. Está dado por 
\begin{equation}
SI(X,Y) = \frac{1}{k - 1} \sum_{i=1}^{k-1} \mathrm{signo} \left(\frac{X_{i+1} - X_i} {Y_{i+1} - Y_i}\right)
\end{equation}
De manera similar al coeficiente de correlación de Pearson, $SI(X,Y)\in [-1, 1]$. 

%
%\subsubsection{Sparsity Promoting Regularization}
%
%Una alternativa a otro tipo de comparaciones es la \textsc{Regularización Promotora de Dispersión o Sparsity Promoting Regularization}, \citeauthor{Engl2009}. La idea consiste en imputar un modelo estadístico a la comparación de mediciones experimentales con modelos de ecuaciones diferenciales. Los operadores diferenciales que no incluyen componentes estocásticos suelen producir trayectorias por lo general suaves, en contraste con la variabilidad existente en las series de tiempo de las mediciones experimentales. 
%
%Sea $\mathbf{p}$ el vector de parámetros de un conjunto de ecuaciones diferenciales. Sea $\Phi(\mathbf{p},t)$ la trayectoria solución dependiente del tiempo $t$ y del vector de parámetros $\mathbf{p}$. Sea $\Psi(\Phi(\mathbf{p},t))$ un modelo Gaussiano del ruido de las mediciones experimentales con desviación estándar constante. El objetivo de añadir $\Phi$  es imputar un criterio estadístico a la trayectoria solución de la ecuación diferencial, y hacer entonces una comparación entre un modelo estadísticos y un conjunto de datos.
%
%Bajo este esquema, se puede buscar minimizar
%\begin{equation}
%J(\mathbf{p}) = \| \Psi(\Phi(\mathbf{p},t)) - X\|_2^2 -\beta \| \mathbf{p} \| _1^1
%\end{equation}
%donde $\beta \in (0,1)$ es un término promotor de la regularización, que se utiliza para ponderar mediante la norma a 1 el desempeño del vector de parámetros $\mathbf{p}$, mientras que $X$ representa los datos contra los cuales se compara el modelo. 

\section{Estrategias de exploración}

Una vez que se tiene definida una función objetivo o función de costo que permita evaluar las distintas soluciones factibles al problema, es necesario contar con una estrategia de búsqueda o exploración que permita explorar el espacio de soluciones factibles. Además, es deseable que la estrategia de búsqueda explore de manera inteligente el espacio de soluciones, es decir, que evite que la búsqueda quede atrapada en puntos extremos locales y que por ende sea imposible encontrar los puntos extremos globales.

\subsection{Tipos de exploración}

Además de la búsqueda al azar, existen dos estrategias generales para resolver problemas de optimización: aquellas basadas en la diferenciabilidad del espacio de soluciones, y aquellas basadas en el uso de criterios heurísticos.
Un ejemplo clásico de un método basado en diferenciabilidad es el de Gradiente Conjugado, \citeauthor{numrecipesc} \citep{numrecipesc}. Entre los métodos populares basados en criterios heurísticos se encuentran el \textsc{Recocido Simulado}, \citeauthor{Kirkpatrick1983} \citep{Kirkpatrick1983}, y los \textsc{Algoritmos Genéticos}, \citeauthor{Goldberg1989} \citep{Goldberg1989}.

Las métodos basados en diferenciabilidad suelen usarse cuando se conoce con un buen nivel de detalle el espacio de soluciones, y en ese caso permiten encontrar los puntos extremos globales fácilmente. Sin embargo, una mala elección del punto inicial de búsqueda puede resultar en que estos algoritmos de optimización queden atrapados en un punto extremo local. Hacer malas elecciones del punto inicial de búsqueda suele ser común cuando no se conoce muy a fondo el espacio de soluciones. Por ello, estos métodos son útiles para refinar soluciones, es decir, para aumentar la precisión de una solución una vez que se cree que se está cerca de un punto extremo global, o al menos, cerca de un punto cuyo valor es cercano al punto extremo global.

Por otro lado, los métodos de búsqueda basados en heurísticas explotan propiedades del problema que no necesariamente están relacionadas con la diferenciabilidad. Además, se ha observado que son más resistentes a quedar atrapados en puntos extremos locales, \citeauthor{BangaMoles2003} \citep{BangaMoles2003}, \citeauthor{Storn1997} \citep{Storn1997}, debido a que incluyen un subprocedimiento que permite variar de una u otra forma las soluciones propuestas, independientemente de si esta solución mejora o no el costo de la función objetivo. Por lo tanto, estos métodos no son tan sensibles a una mala elección del punto o puntos iniciales de búsqueda, y no es necesario conocer la forma específica del espacio de soluciones.

En este trabajo, las estrategias de exploración utilizadas fueron \textsc{Búsqueda Aleatoria}, \textsc{Algoritmos Genéticos} y \textsc{Evolución Diferencial}, cada uno de los cuales se describe a continuación.

\subsubsection{Búsqueda Aleatoria}

La búsqueda aleatoria es la más simple de las estrategias de búsqueda. Consiste en elegir al azar una solución, evaluarla y, si y solo si su costo es mejor que el mejor costo hasta el momento, guardar la solución como la mejor hasta el momento; en caso contrario no se guarda la solución ni se actualiza el valor del mejor costo. En ambos casos, si no se ha llegado a una precisión determinada para la función de costo o bien se ha alcanzado un número máximo de iteraciones, la búsqueda finaliza; en caso contrario, se elige otra solución al azar y se repite el proceso.

\subsubsection{Algoritmos Genéticos}

Inspirados en el trabajo de \citeauthor{holland1975} \citep{holland1975} y tratados de manera un poco más rigurosa por \citeauthor{Goldberg1989} \citep{Goldberg1989}, los algoritmos genéticos son una estrategia de búsqueda que simula el proceso de evolución natural a través de los procesos de cruza, mutación y selección.

El agoritmo inicia con un conjunto de agentes denominados población, donde cada agente tiene un \emph{genoma}, es decir, una representación codificada de una solución al problema de optimización. Posteriormente se selecciona a algunos individuos de la población para procrear a la siguiente generación. La selección se realiza mediante diferentes esquemas, aunque en términos generales se suele favorecer a aquellos individuos que tengan un mejor costo. Los individuos no seleccionados no sobreviven. De entre aquellos que sí han sido seleccionados, se eligen pares de agentes y estos combinan su genoma de acuerdo a algún esquema para crear un tercer agente. Este proceso de cruza se realiza hasta completar una cantidad preestablecida de miembros de la nueva generación. Con cierta probabilidad, por lo general baja, algunos individuos de la nueva población sufrirán una mutación en su genoma. El proceso de selección, cruza y mutación continúa hasta que se ha alcanzado cierta precisión en el costo de la solución o bien se ha alcanzado un número determinado de iteraciones.

Tradicionalmente el genoma y los operadores de los algoritmos genéticos son discretos. Dado que los parámetros que se requirió estimar en este trabajo toman valores continuos, se usó una variante de los algoritmos genéticos tradicionales, adaptados a trabajar con variables continuas encontrado en \citeauthor{Haupt1998} \citep{Haupt1998}, en donde el genoma de un agente se codifica como un vector de valores continuos y los operadores de cruza y mutación pueden ser aplicados a este tipo de variables.

\subsubsection{Evolución Diferencial}

\citeauthor{Storn1997} \citep{Storn1997} observaron que algunos métodos heurísticos existentes no eran tan robustos y no convergían tan rápidamente al ser aplicados a problemas de optimización que involucraran variables continuas. A raíz de esto, desarrollaron un método específicamente pensado para este tipo de problemas. 

El método consiste en una población de soluciones candidato, llamadas agentes. Cada agente se mueve a través del espacio de búsqueda combinando las posiciones de los agentes existentes en la población. Si la nueva posición del agente representa una mejora, esta nueva posición se acepta y pasa a formar parte de la población; en caso contrario, la nueva posición se rechaza. El proceso se repite y se espera que una solución satisfactoria se descubrirá eventualmente.

Sea $x \in \mathbb{R}^n$ un agente en la población de tamaño $NP>3$; sea $F \in [0,2]$, conocido como peso diferencial; sea también $CR \in [0,1]$, la probabilidad de cruza. El algoritmo de evolución diferencial consiste en:
\begin{enumerate}
\item Inicializar cada agente $x$ con una posición aleatoria en el espacio de búsqueda.
\item Hasta que un criterio de búsqueda sea satisfecho, repetir:
	\begin{enumerate}
		\item Escoger al azar tres agentes distintos entre sí $a$, $b$, $c$.
		\item Escoger un índice al azar $R \in {1,\ldots,n}$ donde $n$ es la dimensionalidad del problema
		\item Calcular la posible nueva posición del agente, dada por $y=[y_1,\ldots,y_n]$ iterando sobre cada $i \in {1,\ldots,n}$ como sigue:
			\begin{enumerate}
				\item Elegir al azar de manera uniforme $r \in (0,1)$
				\item Si $i=R$ o $r_i<CR$, hacer $y_i=a_i+F(b_i-c_i)$. En caso contrario $y_i=x_i$
			\end{enumerate}
		\item Si $f(y)<f(x)$, entonces $x=y$
	\end{enumerate}
\item Elegir el agente con el menor costo o máxima adaptación y regresarlo como la mejor solución candidato encontrada.
\end{enumerate}

La elección de $F$, $CR$ y $NP$ puede tener un impacto significativo en el desempeño de la optimización. \citeauthor{Storn1997}  \citep{Storn1997}, y \citeauthor{lampinen2002} \citep{lampinen2002} proporcionan valores iniciales para estos parámetros que parecen ser un buen punto de partida en general.

\section{Justificación del presente trabajo}

Dado que las mediciones experimentales arrojan datos continuos tomados con una frecuencia bastante mayor que la descripción del modelo discreto, la comparación entre dicho modelo y las mediciones experimentales se puede hacer hasta un nivel de detalle limitado. Sería deseable contar con un modelo que pudiera dar una descripción continua en tiempo y estado, además de incorporar asincronía, es decir, que cada componente o nodo de la red actualice su estado de acuerdo a su propio tiempo característico de reacción.

Para este fin bien podría plantearse un modelo basado en \textsc{EDOs}. Sin embargo, para hacerlo sería necesario conocer un conjunto de parámetros relacionados directamente con magnitudes físicas y bioquímicas, a saber: las concentraciones de cada componente de la vía de señalización; las tasas de asociación y disociación de cada complejo bioquímico; la cooperatividad de las reacciones bioquímicas, es decir, la cantidad de moléculas necesarias de un compuesto para que este reaccione con otro. Sin embargo, por lo general estos parámetros no son conocidos en su totalidad y su estimación experimental es o bien costosa o complicada desde el punto de vista de diseño y ejecución del experimento o ambas. Si bien se puede hacer la estimación de algunos de estos parámetros a través de modelos computacionales y de optimización, se requiere de cierto conocimiento previo del sistema para poder llevar a cabo la estimación de manera más dirigida y reducir el espacio de búsqueda.

En el caso particular de esta red de señalización, no todos estos parámetros e información son conocidos, por lo que como primera aproximacion se desarrolló el modelo discreto antes mencionado. Un modelo basado en las ecuaciones de Glass constituye un refinamiento a la descripción del sistema proporcionada por el modelo discreto.

