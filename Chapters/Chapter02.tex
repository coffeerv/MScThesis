%************************************************
\chapter{Materiales y M\'etodos}\label{ch:matmet} % $\mathbb{ZNR}$
%************************************************
%Este capítulo comienza con una discusión de los alcances y limitaciones del modelo discreto a manera de motivación y justificación para el desarrollo de este trabajo. Posteriormente introduce el formalismo de ecuaciones de Glass; plantea el problema de la estimación de parámetros como un problema de optimización, describiendo las nociones de distancia usadas para comparar la dinámica de calcio de Glass con mediciones experimentales; finalmente aborda brevemente el procedimiento seguido para poner en marcha la búsqueda de parámetros.

\section{Scratchpad}
En el caso de la vía de señalización, objeto de estudio de esta tesis, los parámetros a encontrar fueron aquellos tales que reprodujeran el comportamiento del calcio intracelular observado experimentalmente. Se tomó en consideración solamente la similitud en la dinámica de calcio del sistema debido a que éste es el único tipo de dato experimental que cuenta con mediciones largas. Un ejemplo de estas mediciones se muestra en la figura \ref{fig:fluorescencia}.


\subsection{Funciones objetivo}

Es necesario establecer una noción de distancia para determinar si la serie temporal proveniente de los experimentos de fluorescencia de calcio corresponde con la trayectoria del nodo de calcio del modelo de ecuaciones semicontinuas.

\subsubsection{Error Cuadrático Medio (MSE)}


El \textsc{mse} \citep{msewiki} es el cuadrado del valor esperado de la diferencia entre las observaciones y la respuesta, trayectoria o dinámica predicha por un modelo. Al ser minimizado, es posible discriminar entre distintos modelos, estableciendo cuál de entre un conjunto de modelos ajusta mejor, es decir, explica mejor los datos. El \textsc{mse} está dado por $$E[(\hat{\theta} - \theta)^2]$$

\subsubsection{Coeficiente de correlación de Pearson}

El Coeficiente de Correlación de Pearson \citep{pearsoncorrwiki} es una medida de la correlación (dependencia lineal) entre dos variables aleatorias $X$ y $Y$, denotado por $r \in [-1, 1]$, está dado por
\begin{equation} 
r = \frac{\sum_{i=1}^n (X_i - \bar{X})(Y_i - \bar{Y})} {\sqrt{\sum_{i=1}^n (X_i - \bar{X})^2} \sqrt{\sum_{i=1}^n (Y_i - \bar{Y})^2}}
\end{equation}
\\
donde $\bar{X}$ y $\bar{Y}$ son los promedios de $X$ y $Y$, respectivamente, y $X_i$ y $Y_i$ denotan la $i$ésima medición experimental de $X$ y $Y$, respectivamente.

\subsubsection{Índice de Pendiente (SI)}

Propuesto por \citeauthor{Cho2006} \citep{Cho2006}, el índice de pendiente entre dos series de tiempo $X$ y $Y$ consiste en ponderar la suma de los signos de las derivadas entre los puntos de ambas series. Está dado por 
\begin{equation}
SI(X,Y) = \frac{1}{k - 1} \sum_{i=1}^{k-1} \mathrm{signo} \left(\frac{X_{i+1} - X_i} {Y_{i+1} - Y_i}\right)
\end{equation}
De manera similar al coeficiente de correlación de Pearson, $SI(X,Y)\in [-1, 1]$. 

%
%\subsubsection{Sparsity Promoting Regularization}
%
%Una alternativa a otro tipo de comparaciones es la \textsc{Regularización Promotora de Dispersión o Sparsity Promoting Regularization}, \citeauthor{Engl2009}. La idea consiste en imputar un modelo estadístico a la comparación de mediciones experimentales con modelos de ecuaciones diferenciales. Los operadores diferenciales que no incluyen componentes estocásticos suelen producir trayectorias por lo general suaves, en contraste con la variabilidad existente en las series de tiempo de las mediciones experimentales. 
%
%Sea $\mathbf{p}$ el vector de parámetros de un conjunto de ecuaciones diferenciales. Sea $\Phi(\mathbf{p},t)$ la trayectoria solución dependiente del tiempo $t$ y del vector de parámetros $\mathbf{p}$. Sea $\Psi(\Phi(\mathbf{p},t))$ un modelo Gaussiano del ruido de las mediciones experimentales con desviación estándar constante. El objetivo de añadir $\Phi$  es imputar un criterio estadístico a la trayectoria solución de la ecuación diferencial, y hacer entonces una comparación entre un modelo estadísticos y un conjunto de datos.
%
%Bajo este esquema, se puede buscar minimizar
%\begin{equation}
%J(\mathbf{p}) = \| \Psi(\Phi(\mathbf{p},t)) - X\|_2^2 -\beta \| \mathbf{p} \| _1^1
%\end{equation}
%donde $\beta \in (0,1)$ es un término promotor de la regularización, que se utiliza para ponderar mediante la norma a 1 el desempeño del vector de parámetros $\mathbf{p}$, mientras que $X$ representa los datos contra los cuales se compara el modelo. 

En este trabajo, las estrategias de exploración utilizadas fueron \textsc{Búsqueda Aleatoria}, \textsc{Algoritmos Genéticos} y \textsc{Evolución Diferencial}, cada uno de los cuales se describe a continuación.

\subsubsection{Búsqueda Aleatoria}

La búsqueda aleatoria es la más simple de las estrategias de búsqueda. Consiste en elegir al azar una solución, evaluarla y, si y solo si su costo es mejor que el mejor costo hasta el momento, guardar la solución como la mejor hasta el momento; en caso contrario no se guarda la solución ni se actualiza el valor del mejor costo. En ambos casos, si no se ha llegado a una precisión determinada para la función de costo o bien se ha alcanzado un número máximo de iteraciones, la búsqueda finaliza; en caso contrario, se elige otra solución al azar y se repite el proceso.

\subsubsection{Algoritmos Genéticos}

Inspirados en el trabajo de \citeauthor{holland1975} \citep{holland1975} y tratados de manera un poco más rigurosa por \citeauthor{Goldberg1989} \citep{Goldberg1989}, los algoritmos genéticos son una estrategia de búsqueda que simula el proceso de evolución natural a través de los procesos de cruza, mutación y selección.

El agoritmo inicia con un conjunto de agentes denominados población, donde cada agente tiene un \emph{genoma}, es decir, una representación codificada de una solución al problema de optimización. Posteriormente se selecciona a algunos individuos de la población para procrear a la siguiente generación. La selección se realiza mediante diferentes esquemas, aunque en términos generales se suele favorecer a aquellos individuos que tengan un mejor costo. Los individuos no seleccionados no sobreviven. De entre aquellos que sí han sido seleccionados, se eligen pares de agentes y estos combinan su genoma de acuerdo a algún esquema para crear un tercer agente. Este proceso de cruza se realiza hasta completar una cantidad preestablecida de miembros de la nueva generación. Con cierta probabilidad, por lo general baja, algunos individuos de la nueva población sufrirán una mutación en su genoma. El proceso de selección, cruza y mutación continúa hasta que se ha alcanzado cierta precisión en el costo de la solución o bien se ha alcanzado un número determinado de iteraciones.

Tradicionalmente el genoma y los operadores de los algoritmos genéticos son discretos. Dado que los parámetros que se requirió estimar en este trabajo toman valores continuos, se usó una variante de los algoritmos genéticos tradicionales, adaptados a trabajar con variables continuas encontrado en \citeauthor{Haupt1998} \citep{Haupt1998}, en donde el genoma de un agente se codifica como un vector de valores continuos y los operadores de cruza y mutación pueden ser aplicados a este tipo de variables.

\subsubsection{Evolución Diferencial}

\citeauthor{Storn1997} \citep{Storn1997} observaron que algunos métodos heurísticos existentes no eran tan robustos y no convergían tan rápidamente al ser aplicados a problemas de optimización que involucraran variables continuas. A raíz de esto, desarrollaron un método específicamente pensado para este tipo de problemas. 

El método consiste en una población de soluciones candidato, llamadas agentes. Cada agente se mueve a través del espacio de búsqueda combinando las posiciones de los agentes existentes en la población. Si la nueva posición del agente representa una mejora, esta nueva posición se acepta y pasa a formar parte de la población; en caso contrario, la nueva posición se rechaza. El proceso se repite y se espera que una solución satisfactoria se descubrirá eventualmente.

Sea $x \in \mathbb{R}^n$ un agente en la población de tamaño $NP>3$; sea $F \in [0,2]$, conocido como peso diferencial; sea también $CR \in [0,1]$, la probabilidad de cruza. El algoritmo de evolución diferencial consiste en:
\begin{enumerate}
\item Inicializar cada agente $x$ con una posición aleatoria en el espacio de búsqueda.
\item Hasta que un criterio de búsqueda sea satisfecho, repetir:
	\begin{enumerate}
		\item Escoger al azar tres agentes distintos entre sí $a$, $b$, $c$.
		\item Escoger un índice al azar $R \in {1,\ldots,n}$ donde $n$ es la dimensionalidad del problema
		\item Calcular la posible nueva posición del agente, dada por $y=[y_1,\ldots,y_n]$ iterando sobre cada $i \in {1,\ldots,n}$ como sigue:
			\begin{enumerate}
				\item Elegir al azar de manera uniforme $r \in (0,1)$
				\item Si $i=R$ o $r_i<CR$, hacer $y_i=a_i+F(b_i-c_i)$. En caso contrario $y_i=x_i$
			\end{enumerate}
		\item Si $f(y)<f(x)$, entonces $x=y$
	\end{enumerate}
\item Elegir el agente con el menor costo o máxima adaptación y regresarlo como la mejor solución candidato encontrada.
\end{enumerate}

La elección de $F$, $CR$ y $NP$ puede tener un impacto significativo en el desempeño de la optimización. \citeauthor{Storn1997}  \citep{Storn1997}, y \citeauthor{lampinen2002} \citep{lampinen2002} proporcionan valores iniciales para estos parámetros que parecen ser un buen punto de partida en general.



